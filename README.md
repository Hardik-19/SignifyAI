# SignifyAI
This project introduces a real-time  platform that improves accessibility in online education through cutting-edge technological solutions.
Speech-to-Text Conversion : The system uses advanced speech recognition models like DeepSpeech or Google Speech-to-Text API to convert spoken language into text in real-time, enabling immediate processing for accessibility features.
Text Processing & Mapping : The transcribed text undergoes natural language processing (NLP) to identify key phrases and map them to predefined sign language gestures using a text-to-sign language dictionary.
3D Avatar Animation : Blender is used to design and animate a 3D avatar, which dynamically performs sign language gestures based on the mapped text, ensuring accurate and visually engaging communication.
Nvidia Jetson Nano : The NVIDIA Jetson Nano's GPU acceleration allows efficient, low-latency processing of audio, text, video, and animations, making the platform capable of real-time performance without reliance on cloud computing.
